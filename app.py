
import streamlit as st
import pandas as pd
import plotly.express as px

st.set_page_config(page_title="æ©Ÿæ§‹å€‹æ¡ˆé¡åº¦ä½¿ç”¨ç‡åˆ†æ", layout="wide")

# --- Constants & Config ---
REQUIRED_COLUMNS = [
    'æœˆä»½', 'æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 
    'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)', 
    'æœå‹™é …ç›®', 'æ”¿åºœæœå‹™é …ç›®å–®åƒ¹', 'æœå‹™ç´€éŒ„çµ„æ•¸', 'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦',
    'æœå‹™ä½¿ç”¨ç‹€æ…‹' # Added per request. If missing, we will handle it.
]

import io

# --- Helper Functions ---
def clean_currency_column(series):
    """Removes commas and converts to float."""
    return pd.to_numeric(series.astype(str).str.replace(',', ''), errors='coerce').fillna(0)

@st.cache_data
def convert_df_to_excel(df):
    """Converts DataFrame to Excel bytes."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False)
    return output.getvalue()

@st.cache_data
def load_data(file):
    """Loads and cleans the data from Excel."""
    try:
        df = pd.read_excel(file)
        
        # Soft check for 'æœå‹™ä½¿ç”¨ç‹€æ…‹' - if missing, warn but don't fail?
        # Or strict? Let's be strict if the user specifically asked for it, 
        # but let's allow it to be optional for backward compatibility if file is old.
        if 'æœå‹™ä½¿ç”¨ç‹€æ…‹' not in df.columns:
            # Try to match fuzzy? No, just add placeholder
            df['æœå‹™ä½¿ç”¨ç‹€æ…‹'] = 'æœªçŸ¥'
        
        # Verify columns exist (excluding valid optional ones if any)
        # We enforce REQUIRED_COLUMNS now
        missing_cols = [col for col in REQUIRED_COLUMNS if col not in df.columns]
        if missing_cols:
             st.error(f"Missing columns in uploaded file: {missing_cols}")
             return None

        # Clean numeric columns
        df['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'] = clean_currency_column(df['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'])
        df['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] = clean_currency_column(df['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'])
        df['æ”¿åºœæœå‹™é …ç›®å–®åƒ¹'] = clean_currency_column(df['æ”¿åºœæœå‹™é …ç›®å–®åƒ¹'])
        df['æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦'] = clean_currency_column(df['æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦']) # Ensure detail cost is also numeric
        
        # Optimize Month for sorting: Try to convert to Int if possible
        try:
            df['æœˆä»½'] = pd.to_numeric(df['æœˆä»½'], errors='coerce').fillna(0).astype(int)
        except:
            pass 

        return df
    except Exception as e:
        st.error(f"Error loading file: {e}")
        return None

def get_monthly_aggregated_data(df):
    """
    Aggregates data to the Case-Month level.
    Rule: 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦' and 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)' are repeated per row, so take MAX.
    """
    # Group by key identifiers
    grouped = df.groupby(['æœˆä»½', 'æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ']).agg({
        'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦': 'max',
        'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': 'max',
        'æœå‹™ä½¿ç”¨ç‹€æ…‹': 'first' # Take the first value found for this case-month
    }).reset_index()
    
    return grouped

# --- Main App ---
def main():
    st.title("ğŸ¡æ©Ÿæ§‹å€‹æ¡ˆé¡åº¦ä½¿ç”¨ç‡åˆ†æ App")

    # --- Sidebar ---
    st.sidebar.header("è¨­å®š")
    uploaded_file = st.sidebar.file_uploader("ä¸Šå‚³ Excel æª”æ¡ˆ", type=['xlsx', 'xls'])
    
    if uploaded_file is None:
        st.info("è«‹å…ˆä¸Šå‚³è³‡æ–™æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
        return

    # Load Data
    raw_df = load_data(uploaded_file)
    if raw_df is None:
        return

    # Create Aggregated DF for High-level analysis
    agg_df = get_monthly_aggregated_data(raw_df)

    # Navigation
    page = st.sidebar.radio(
        "é¸æ“‡é é¢",
        ["æ©Ÿæ§‹ç¸½è¦½", "é›™æœˆæ¯”è¼ƒåˆ†æ", "æœå‹™ç‹€æ…‹çµ±è¨ˆ", "ç£å°/äººå“¡ç¸¾æ•ˆ", "æœå‹™é …ç›®åˆ†æ", "ç•°å¸¸å€‹æ¡ˆè­¦ç¤º", "å€‹æ¡ˆè©³ç´°åˆ†æ"]
    )

    if page == "æ©Ÿæ§‹ç¸½è¦½":
        page_agency_overview(agg_df)
    elif page == "é›™æœˆæ¯”è¼ƒåˆ†æ":
        page_comparison(agg_df)
    elif page == "æœå‹™ç‹€æ…‹çµ±è¨ˆ":
        page_status_stats(agg_df)
    elif page == "ç£å°/äººå“¡ç¸¾æ•ˆ":
        page_supervisor_performance(agg_df)
    elif page == "æœå‹™é …ç›®åˆ†æ":
        page_service_analysis(raw_df)
    elif page == "ç•°å¸¸å€‹æ¡ˆè­¦ç¤º":
        page_abnormal_alerts(agg_df)
    elif page == "å€‹æ¡ˆè©³ç´°åˆ†æ":
        page_case_detail(raw_df, agg_df)

# --- Pages ---

def page_status_stats(agg_df):
    st.header("ğŸ“‹ æ©Ÿæ§‹æœå‹™ç‹€æ…‹çµ±è¨ˆ")
    
    # Filter Agency (Optional)
    agencies = agg_df['æ©Ÿæ§‹'].unique()
    selected_agency = st.selectbox("é¸æ“‡æ©Ÿæ§‹ (å…¨é¸å‰‡ä¸å¡«)", ["å…¨éƒ¨"] + list(agencies), key='status_agency')
    
    df_to_use = agg_df.copy()
    if selected_agency != "å…¨éƒ¨":
        df_to_use = df_to_use[df_to_use['æ©Ÿæ§‹'] == selected_agency]

    # Simplify Status Logic
    def simplify_status(s):
        s = str(s)
        if s.startswith('æœå‹™ä¸­'):
            return 'æœå‹™ä¸­'
        elif s.startswith('æš«åœ'):
            return 'æš«åœ'
        elif s.startswith('çµæ¡ˆ'):
            return 'çµæ¡ˆ'
        else:
            return s # Or 'å…¶ä»–' if strict

    df_to_use['æœå‹™ä½¿ç”¨ç‹€æ…‹'] = df_to_use['æœå‹™ä½¿ç”¨ç‹€æ…‹'].apply(simplify_status)

    # Aggregate: Group by Month, Agency, Status -> Count Cases
    status_counts = df_to_use.groupby(['æœˆä»½', 'æ©Ÿæ§‹', 'æœå‹™ä½¿ç”¨ç‹€æ…‹']).agg({
        'å€‹æ¡ˆ': 'count'
    }).rename(columns={'å€‹æ¡ˆ': 'äººæ•¸'}).reset_index()
    
    # Aggregate for Chart: If "All", group by [Month, Status] only to get clean total bars
    if selected_agency == "å…¨éƒ¨":
        chart_data = df_to_use.groupby(['æœˆä»½', 'æœå‹™ä½¿ç”¨ç‹€æ…‹']).agg({'å€‹æ¡ˆ': 'count'}).rename(columns={'å€‹æ¡ˆ': 'äººæ•¸'}).reset_index()
    else:
        chart_data = status_counts # Already grouped by [Month, Agency, Status]

    # Visualization: Stacked Bar Chart
    # X=Month, Y=Count, Color=Status
    title_str = f"{selected_agency} - æ¯æœˆæœå‹™ç‹€æ…‹äººæ•¸çµ±è¨ˆ" if selected_agency != "å…¨éƒ¨" else "å…¨æ©Ÿæ§‹ - æ¯æœˆæœå‹™ç‹€æ…‹äººæ•¸çµ±è¨ˆ"
    
    fig = px.bar(
        chart_data, 
        x='æœˆä»½', 
        y='äººæ•¸', 
        color='æœå‹™ä½¿ç”¨ç‹€æ…‹', 
        text='äººæ•¸',
        title=title_str,
        barmode='stack' # Force stacked for cleaner look
    )
    fig.update_xaxes(type='category')
    fig.update_traces(textangle=0, textposition='inside', width=0.15) # Force horizontal text inside bars, make bars thinner
    fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide', bargap=0.2) # Hide too small text
    st.plotly_chart(fig, use_container_width=True)
    
    # --- Growth Momentum (New) ---
    st.subheader("ğŸ“ˆ æ©Ÿæ§‹æˆé•·å‹•èƒ½åˆ†æ (æ·¨æˆé•·)")
    # Calculate Active Count Trend
    # Filter only 'æœå‹™ä¸­'
    active_df = df_to_use[df_to_use['æœå‹™ä½¿ç”¨ç‹€æ…‹'] == 'æœå‹™ä¸­']
    
    # Define months for reindexing to ensure continuity
    months = sorted(agg_df['æœˆä»½'].unique())
    
    if not active_df.empty:
        active_trend = active_df.groupby(['æœˆä»½']).agg({'å€‹æ¡ˆ': 'count'}).rename(columns={'å€‹æ¡ˆ': 'æœå‹™ä¸­äººæ•¸'}).reindex(months, fill_value=0).reset_index()
        # Calculate Delta
        active_trend['æ·¨æˆé•·'] = active_trend['æœå‹™ä¸­äººæ•¸'].diff().fillna(0)
        
        fig_growth = px.bar(
            active_trend, 
            x='æœˆä»½', 
            y='æ·¨æˆé•·', 
            text='æ·¨æˆé•·',
            title=f"{selected_agency} - æ¯æœˆå€‹æ¡ˆæ·¨æˆé•·æ•¸",
            color='æ·¨æˆé•·',
            color_continuous_scale=['red', 'gray', 'green'] # Red for negative, Green for positive
        )
        fig_growth.update_xaxes(type='category')
        fig_growth.update_traces(width=0.2) # Make bars narrower
        st.plotly_chart(fig_growth, use_container_width=True)
    else:
        st.info("å°šç„¡æœå‹™ä¸­å€‹æ¡ˆæ•¸æ“šå¯è¨ˆç®—æˆé•·å‹•èƒ½ã€‚")

    # Pivot Table for clearer view
    pivot_table = status_counts.pivot_table(
        index=['æœˆä»½', 'æ©Ÿæ§‹'], 
        columns='æœå‹™ä½¿ç”¨ç‹€æ…‹', 
        values='äººæ•¸', 
        fill_value=0,
        aggfunc='sum' # Should be sum of counts
    ).astype(int)
    
    st.subheader("è©³ç´°æ•¸æ“šè¡¨")
    st.dataframe(pivot_table)
    
    # Export
    excel_data = convert_df_to_excel(pivot_table.reset_index())
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰ç‹€æ…‹çµ±è¨ˆè¡¨",
        data=excel_data,
        file_name='æ¯æœˆæœå‹™ç‹€æ…‹çµ±è¨ˆ.xlsx',
        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

def page_service_analysis(raw_df):
    st.header("ğŸ“Š æœå‹™é …ç›®åˆ†æ")
    
    # Filter by Month (Optional, but good for drilling down)
    months = sorted(raw_df['æœˆä»½'].unique())
    selected_month = st.selectbox("é¸æ“‡æœˆä»½ (å…¨é¸å‰‡ä¸å¡«)", ["å…¨å¹´åº¦"] + list(months))
    
    df_to_use = raw_df.copy()
    if selected_month != "å…¨å¹´åº¦":
        df_to_use = df_to_use[df_to_use['æœˆä»½'] == selected_month]

    # Aggregate by Service Item
    # Metric 1: Total Cost (Sum of æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦)
    # Metric 2: Frequency (Count of rows) - assuming 1 row = 1 record. 
    # Or sum of 'æœå‹™ç´€éŒ„çµ„æ•¸' if that represents units providing value. Let's use Count for frequency first (Usage Count).
    
    # Check if 'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦' is numeric
    # It should be from load_data
    
    service_agg = df_to_use.groupby('æœå‹™é …ç›®').agg({
        'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': 'sum',
        'å€‹æ¡ˆ': 'count' # Proxy for frequency key
    }).rename(columns={'å€‹æ¡ˆ': 'ä½¿ç”¨æ¬¡æ•¸', 'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': 'ç¸½é‡‘é¡'}).reset_index()
    
    # Top 20 by Cost
    top_cost = service_agg.sort_values('ç¸½é‡‘é¡', ascending=False).head(20)
    
    st.subheader(f"ğŸ’° èŠ±è²»æœ€é«˜çš„å‰ 20 é …æœå‹™ ({selected_month})")
    fig_cost = px.bar(top_cost, x='ç¸½é‡‘é¡', y='æœå‹™é …ç›®', orientation='h', title='æœå‹™é …ç›®ç¸½é‡‘é¡æ’å', text_auto='.2s')
    fig_cost.update_layout(yaxis={'categoryorder':'total ascending'})
    fig_cost.update_traces(width=0.6) # Slightly thicker for horizontal bars to remain readable
    st.plotly_chart(fig_cost, use_container_width=True)
    
    # Top 20 by Frequency
    top_freq = service_agg.sort_values('ä½¿ç”¨æ¬¡æ•¸', ascending=False).head(20)
    
    st.subheader(f"ğŸ”„ ä½¿ç”¨é »ç‡æœ€é«˜çš„å‰ 20 é …æœå‹™ ({selected_month})")
    fig_freq = px.bar(top_freq, x='ä½¿ç”¨æ¬¡æ•¸', y='æœå‹™é …ç›®', orientation='h', title='æœå‹™é …ç›®ä½¿ç”¨æ¬¡æ•¸æ’å', text_auto=True)
    fig_freq.update_layout(yaxis={'categoryorder':'total ascending'})
    fig_freq.update_traces(width=0.6)
    st.plotly_chart(fig_freq, use_container_width=True)

    # --- Cost Structure Analysis (New) ---
    st.markdown("---")
    st.subheader(f"ğŸ¥§ ç¶“è²»çµæ§‹åˆ†æ ({selected_month})")
    
    def categorize_service(item_name):
        item_name = str(item_name) # Ensure string for inclusion check
        if any(x in item_name for x in ['æ²æµ´', 'èº«é«”', 'æ´—é ­', 'è‚¢é«”']): 
            return 'èº«é«”ç…§é¡§'
        elif any(x in item_name for x in ['å®¶å‹™', 'é™ªåŒ', 'ä»£è³¼', 'é¤']): 
            return 'æ—¥å¸¸ç”Ÿæ´»ç…§é¡§'
        elif any(x in item_name for x in ['å¾©èƒ½', 'è­·ç†', 'ç‡Ÿé¤Š']): 
            return 'å°ˆæ¥­æœå‹™'
        elif any(x in item_name for x in ['å–˜æ¯']): 
            return 'å–˜æ¯æœå‹™'
        else:
            return 'å…¶ä»–'
            
    df_to_use['é¡åˆ¥'] = df_to_use['æœå‹™é …ç›®'].apply(categorize_service)
    
    df_to_use['é¡åˆ¥'] = df_to_use['æœå‹™é …ç›®'].apply(categorize_service)
    
    # Treemap Data Preparation
    treemap_data = df_to_use.groupby(['é¡åˆ¥', 'æœå‹™é …ç›®']).agg({'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': 'sum'}).reset_index()
    # Filter out 0 or negative values
    treemap_data = treemap_data[treemap_data['æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦'] > 0]
    
    if not treemap_data.empty:
        fig_tree = px.treemap(
            treemap_data, 
            path=['é¡åˆ¥', 'æœå‹™é …ç›®'], 
            values='æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦',
            title=f'ç¶“è²»çµæ§‹èˆ‡æœå‹™ç´°é …åˆ†æ ({selected_month})',
            color='é¡åˆ¥', # Color by Category to keep it structured
            color_discrete_map={ # Optional: Define nice colors if needed, or let Plotly decide
                'èº«é«”ç…§é¡§': '#e74c3c', 
                'æ—¥å¸¸ç”Ÿæ´»ç…§é¡§': '#3498db', 
                'å°ˆæ¥­æœå‹™': '#f1c40f', 
                'å–˜æ¯æœå‹™': '#2ecc71', 
                'å…¶ä»–': '#95a5a6'
            }
        )
        fig_tree.update_traces(textinfo='label+value+percent entry')
        st.plotly_chart(fig_tree, use_container_width=True)
    else:
        st.info("ç„¡æœ‰æ•ˆæ•¸æ“šå¯ç¹ªè£½ç¶“è²»çµæ§‹åœ–ã€‚")

def page_abnormal_alerts(agg_df):
    st.header("ğŸš¨ ç•°å¸¸å€‹æ¡ˆè­¦ç¤º")
    
    # Filters in Sidebar
    months = sorted(agg_df['æœˆä»½'].unique())
    selected_month = st.sidebar.selectbox("ç•°å¸¸è­¦ç¤º-é¸æ“‡æœˆä»½", months, index=len(months)-1 if months else 0)
    
    agencies = agg_df['æ©Ÿæ§‹'].unique()
    selected_agency = st.sidebar.selectbox("ç•°å¸¸è­¦ç¤º-é¸æ“‡æ©Ÿæ§‹", ["å…¨éƒ¨"] + list(agencies))
    
    # Filter Data
    current_data = agg_df[agg_df['æœˆä»½'] == selected_month].copy()
    if selected_agency != "å…¨éƒ¨":
        current_data = current_data[current_data['æ©Ÿæ§‹'] == selected_agency]
        
    # Calculate Rate
    current_data['Rate'] = (current_data['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / current_data['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100).round(2)
    
    # Thresholds
    low_threshold = 30
    high_threshold = 95
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“‰ ä½ä½¿ç”¨ç‡è­¦ç¤º (<30%)", "ğŸ“ˆ é«˜ä½¿ç”¨ç‡è­¦ç¤º (>95%)", "ğŸ† è²¢ç»åº¦ 80/20 æ³•å‰‡ (VIP)", "ğŸ§¨ é©Ÿè·Œé è­¦ (MoM > 30%)", "ğŸ“‰ é€£çºŒè¡°é€€è­¦ç¤º (é€£çºŒ3æœˆä¸‹æ»‘)"])
    
    with tab1:
        low_usage = current_data[current_data['Rate'] < low_threshold].sort_values('Rate')
        st.warning(f"å…±æœ‰ {len(low_usage)} ä½å€‹æ¡ˆä½¿ç”¨ç‡ä½æ–¼ {low_threshold}%")
        
        # Download Button for Low Usage
        if not low_usage.empty:
            excel_data = convert_df_to_excel(low_usage)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ä½ä½¿ç”¨ç‡å€‹æ¡ˆæ¸…å–®",
                data=excel_data,
                file_name=f'ä½ä½¿ç”¨ç‡å€‹æ¡ˆ_{selected_month}æœˆ.xlsx',
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                key='dl_low'
            )

        st.dataframe(
            low_usage[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'æœå‹™ä½¿ç”¨ç‹€æ…‹', 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)', 'Rate']],
            column_config={
                "Rate": st.column_config.ProgressColumn(
                    "ä½¿ç”¨ç‡ (%)",
                    help="é¡åº¦ä½¿ç”¨ç‡",
                    format="%.2f%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦": st.column_config.NumberColumn(format="$%d"),
                "æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)": st.column_config.NumberColumn(format="$%d"),
            },
            hide_index=True,
            use_container_width=True
        )
        
    with tab2:
        high_usage = current_data[current_data['Rate'] > high_threshold].sort_values('Rate', ascending=False)
        st.error(f"å…±æœ‰ {len(high_usage)} ä½å€‹æ¡ˆä½¿ç”¨ç‡é«˜æ–¼ {high_threshold}%")
        
        # Download Button for High Usage
        if not high_usage.empty:
            excel_data = convert_df_to_excel(high_usage)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰é«˜ä½¿ç”¨ç‡å€‹æ¡ˆæ¸…å–®",
                data=excel_data,
                file_name=f'é«˜ä½¿ç”¨ç‡å€‹æ¡ˆ_{selected_month}æœˆ.xlsx',
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                key='dl_high'
            )

        st.dataframe(
            high_usage[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'æœå‹™ä½¿ç”¨ç‹€æ…‹', 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)', 'Rate']],
            column_config={
                "Rate": st.column_config.ProgressColumn(
                    "ä½¿ç”¨ç‡ (%)",
                    help="é¡åº¦ä½¿ç”¨ç‡",
                    format="%.2f%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦": st.column_config.NumberColumn(format="$%d"),
                "æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)": st.column_config.NumberColumn(format="$%d"),
            },
            hide_index=True,
            use_container_width=True
        )

    with tab3:
        # Pareto Principle (80/20 Rule)
        # Sort by Revenue
        vip_data = current_data.sort_values('æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)', ascending=False).copy()
        total_revenue = vip_data['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
        vip_data['ç´¯ç©ç‡Ÿæ”¶'] = vip_data['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].cumsum()
        vip_data['ç´¯ç©ä½”æ¯”(%)'] = (vip_data['ç´¯ç©ç‡Ÿæ”¶'] / total_revenue * 100)
        
        # Find the cut-off for 80% revenue
        vip_80 = vip_data[vip_data['ç´¯ç©ä½”æ¯”(%)'] <= 80]
        # If very few, take at least top 10
        if len(vip_80) == 0 and not vip_data.empty:
            vip_80 = vip_data.head(10) # Fallback
            
        count_vip = len(vip_80)
        count_total = len(vip_data)
        percent_vip = (count_vip / count_total * 100) if count_total > 0 else 0
        
        st.success(f"æœ¬æœˆå‰ {count_vip} ä½ (ç´„ {percent_vip:.1f}%) å€‹æ¡ˆè²¢ç»äº† 80% çš„ç‡Ÿæ”¶æœå‹™è²»ã€‚")
        
        # Download Button for VIP
        if not vip_80.empty:
            excel_data = convert_df_to_excel(vip_80)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ VIP é«˜è²¢ç»åå–®",
                data=excel_data,
                file_name=f'VIPå€‹æ¡ˆ_{selected_month}æœˆ.xlsx',
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                key='dl_vip'
            )

        st.dataframe(
            vip_80[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'æœå‹™ä½¿ç”¨ç‹€æ…‹', 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)', 'ç´¯ç©ä½”æ¯”(%)']]
            .style.format({'ç´¯ç©ä½”æ¯”(%)': '{:.1f}%', 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦': '{:,.0f}', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': '{:,.0f}'})
        )

    with tab4:
        # Sudden Drop Analysis
        # We need to compare "selected_month" vs "selected_month - 1"
        # Since months are integers (e.g., 9, 10, 11), prev_month is simple subtraction
        prev_month = selected_month - 1
        
        if prev_month not in sorted(agg_df['æœˆä»½'].unique()):
            st.info(f"ç„¡æ³•è¨ˆç®—é©Ÿè·Œé è­¦ï¼Œå› ç‚ºæ‰¾ä¸åˆ°ä¸Šä¸€æœŸ ({prev_month}æœˆ) çš„æ•¸æ“šã€‚")
        else:
            # Prepare Previous Month Data
            prev_data = agg_df[agg_df['æœˆä»½'] == prev_month].copy()
            prev_data['Rate_Prev'] = (prev_data['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / prev_data['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)
            
            # Prepare Current Data (already filtered as current_data)
            # We need to merge on [Agency, Staff, Case]
            merged_drop = current_data.merge(
                prev_data[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_Prev']], 
                on=['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ'], 
                how='inner',
                suffixes=('', '_Prev')
            )
            
            # Calculate Drop
            merged_drop['Drop'] = merged_drop['Rate_Prev'] - merged_drop['Rate']
            
            # Filter for sudden drop > 30%
            sudden_drop_cases = merged_drop[merged_drop['Drop'] > 30].sort_values('Drop', ascending=False)
            
            st.error(f"å…±æœ‰ {len(sudden_drop_cases)} ä½å€‹æ¡ˆä½¿ç”¨ç‡è¼ƒä¸Šæœˆé©Ÿè·Œè¶…é 30%")
            
            if not sudden_drop_cases.empty:
                excel_drop = convert_df_to_excel(sudden_drop_cases)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰é©Ÿè·Œå€‹æ¡ˆæ¸…å–®",
                    data=excel_drop,
                    file_name=f'é©Ÿè·Œå€‹æ¡ˆ_{selected_month}æœˆ.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    key='dl_drop'
                )

                st.dataframe(
                    sudden_drop_cases[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'æœå‹™ä½¿ç”¨ç‹€æ…‹', 'Rate_Prev', 'Rate', 'Drop']]
                    .rename(columns={'Rate_Prev': 'ä¸Šæœˆ(%)', 'Rate': 'æœ¬æœˆ(%)', 'Drop': 'è·Œå¹…(%)'})
                    .style.format({'ä¸Šæœˆ(%)': '{:.1f}%', 'æœ¬æœˆ(%)': '{:.1f}%', 'è·Œå¹…(%)': '{:.1f}%'})
                )

    with tab5:
        # Churn Risk: Continuous Decline over 3 months
        # T (selected), T-1, T-2
        m1 = selected_month
        m2 = m1 - 1
        m3 = m1 - 2
        
        valid_months = sorted(agg_df['æœˆä»½'].unique())
        
        if m2 not in valid_months or m3 not in valid_months:
             st.info(f"ç„¡æ³•è¨ˆç®—é€£çºŒè¡°é€€é è­¦ï¼Œå› ç‚ºéœ€è¦é€£çºŒä¸‰å€‹æœˆçš„æ•¸æ“š (éœ€åŒ…å« {m2}æœˆ, {m3}æœˆ)ã€‚")
        else:
            # Prepare Dataframes
            # We need Agency, Staff, Case, Rate for M1, M2, M3
            cols_needed = ['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)']
            
            df1 = agg_df[agg_df['æœˆä»½'] == m1][cols_needed].copy()
            df2 = agg_df[agg_df['æœˆä»½'] == m2][cols_needed].copy()
            df3 = agg_df[agg_df['æœˆä»½'] == m3][cols_needed].copy()
            
            # Filter Agency if needed
            if selected_agency != "å…¨éƒ¨":
                df1 = df1[df1['æ©Ÿæ§‹'] == selected_agency]
                df2 = df2[df2['æ©Ÿæ§‹'] == selected_agency]
                df3 = df3[df3['æ©Ÿæ§‹'] == selected_agency]

            # Calc Rates
            def calc_rate_series(df):
                return (df['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / df['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)

            df1['Rate_M1'] = calc_rate_series(df1)
            df2['Rate_M2'] = calc_rate_series(df2)
            df3['Rate_M3'] = calc_rate_series(df3)
            
            # Merge
            # Inner join because we need the case to exist in all 3 months to say "continuous" decline?
            # Or left join? If a case didn't exist in m3, it's not a "decline" from m3. So Inner is safer for specific "Churn Risk" definition.
            merge_base = df1[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_M1', 'æœå‹™ä½¿ç”¨ç‹€æ…‹'] if 'æœå‹™ä½¿ç”¨ç‹€æ…‹' in df1.columns else ['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_M1']]
            if 'æœå‹™ä½¿ç”¨ç‹€æ…‹' not in merge_base.columns:
                 # Try adding status from df1
                 status_map = agg_df[agg_df['æœˆä»½'] == m1][['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'æœå‹™ä½¿ç”¨ç‹€æ…‹']].drop_duplicates()
                 merge_base = merge_base.merge(status_map, on=['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ'], how='left')

            m_churn = merge_base.merge(
                df2[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_M2']], on=['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ'], how='inner'
            ).merge(
                df3[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_M3']], on=['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ'], how='inner'
            )
            
            # Check Logic: Rate_M3 > Rate_M2 > Rate_M1
            # Filter: strict decline
            churn_risk = m_churn[
                (m_churn['Rate_M3'] > m_churn['Rate_M2']) & 
                (m_churn['Rate_M2'] > m_churn['Rate_M1'])
            ].copy()
            
            # Calculate Total Drop
            churn_risk['ç¸½è·Œå¹…'] = churn_risk['Rate_M3'] - churn_risk['Rate_M1']
            
            # Sort by Total Drop
            churn_risk = churn_risk.sort_values('ç¸½è·Œå¹…', ascending=False)
            
            st.error(f"âš ï¸ å…±æœ‰ {len(churn_risk)} ä½å€‹æ¡ˆå‘ˆç¾é€£çºŒä¸‰å€‹æœˆä½¿ç”¨ç‡ä¸‹æ»‘")
            
            if not churn_risk.empty:
                excel_churn = convert_df_to_excel(churn_risk)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰æµå¤±é¢¨éšªå€‹æ¡ˆæ¸…å–®",
                    data=excel_churn,
                    file_name=f'æµå¤±é¢¨éšªå€‹æ¡ˆ_{selected_month}æœˆ.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    key='dl_churn'
                )

                st.dataframe(
                    churn_risk[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'æœå‹™ä½¿ç”¨ç‹€æ…‹', 'Rate_M3', 'Rate_M2', 'Rate_M1', 'ç¸½è·Œå¹…']]
                    .rename(columns={
                        'Rate_M3': f'{m3}æœˆ(%)', 
                        'Rate_M2': f'{m2}æœˆ(%)', 
                        'Rate_M1': f'{m1}æœˆ(%)'
                    })
                    .style.format({
                        f'{m3}æœˆ(%)': '{:.1f}%', 
                        f'{m2}æœˆ(%)': '{:.1f}%', 
                        f'{m1}æœˆ(%)': '{:.1f}%',
                        'ç¸½è·Œå¹…': '{:.1f}%'
                    })
                    .background_gradient(subset=['ç¸½è·Œå¹…'], cmap='Reds')
                )

def page_agency_overview(agg_df):
    st.header("ğŸ“Š æ©Ÿæ§‹é¡åº¦ä½¿ç”¨ç‡ç¸½è¦½")
    
    # Logic: Group by [Month, Agency], Sum(Used) / Sum(Quota)
    agency_monthly = agg_df.groupby(['æœˆä»½', 'æ©Ÿæ§‹']).agg({
        'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦': 'sum',
        'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': 'sum'
    }).reset_index()
    
    agency_monthly['ä½¿ç”¨ç‡(%)'] = (agency_monthly['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / agency_monthly['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100).round(2)
    
    # --- Executive Metric Cards (New) ---
    st.markdown("### ğŸ  ç¶“ç‡Ÿé—œéµæŒ‡æ¨™ (KPI)")
    total_revenue = agency_monthly['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
    total_quota = agency_monthly['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].sum()
    avg_rate_total = (total_revenue / total_quota * 100) if total_quota > 0 else 0
    total_cases = agg_df[agg_df['æœˆä»½'].isin(agency_monthly['æœˆä»½'])]['å€‹æ¡ˆ'].nunique() # Approx
    # Actually metrics should probably be based on the "Latest Month" or "Selected Period Avg"?
    # Agency Overview chart shows trend, but metrics usually need a specific context. 
    # Let's show "Average Monthly Performance" or "Total YTD".
    # Given the chart is monthly trend, let's show totals for the *visible data*.
    
    kpi1, kpi2, kpi3 = st.columns(3)
    kpi1.metric("ç¸½æœå‹™é‡‘é¡ (ç´¯è¨ˆ)", f"${total_revenue:,.0f}")
    kpi2.metric("å¹³å‡é¡åº¦ä½¿ç”¨ç‡", f"{avg_rate_total:.1f}%")
    kpi3.metric("ç¸½æœå‹™äººæ¬¡ (ç´¯è¨ˆ)", f"{total_cases:,.0f}") # Sum of monthly counts

    # --- Automated Insights (New) ---
    # Calculate variables for insights
    avg_rate = avg_rate_total # Using the overall average rate
    gap = (total_quota * 0.85 - total_revenue) # Potential revenue if rate reaches 85%

    analysis_text = "**ğŸ“ æœˆå ±æ‘˜è¦ï¼š**\n"

    # Calculate MoM Growth (Revenue & Cases) Breakdown by Agency
    months_sorted = sorted(agg_df['æœˆä»½'].unique())
    if len(months_sorted) >= 2:
        curr_m = months_sorted[-1]
        prev_m = months_sorted[-2]
        
        analysis_text += f"\n    - {curr_m}æœˆèˆ‡ä¸Šæœˆæ©Ÿæ§‹å‹•èƒ½æ¯”è¼ƒ (ç‡Ÿæ”¶ / æ´»èºå€‹æ¡ˆ)ï¼š"
        
        agencies = sorted(agg_df['æ©Ÿæ§‹'].unique())
        for agency in agencies:
            curr_stats = agg_df[(agg_df['æœˆä»½'] == curr_m) & (agg_df['æ©Ÿæ§‹'] == agency)]
            prev_stats = agg_df[(agg_df['æœˆä»½'] == prev_m) & (agg_df['æ©Ÿæ§‹'] == agency)]
            
            # Revenue
            curr_rev = curr_stats['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
            prev_rev = prev_stats['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
            rev_diff = curr_rev - prev_rev
            
            # Active Cases
            curr_cases = curr_stats[curr_stats['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] > 0]['å€‹æ¡ˆ'].nunique()
            prev_cases = prev_stats[prev_stats['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] > 0]['å€‹æ¡ˆ'].nunique()
            case_diff = curr_cases - prev_cases
            
            # Formatting with Colors (Using HTML for compatibility)
            # Green: #2ecc71, Red: #e74c3c, Gray: #95a5a6
            rev_str = f"+${rev_diff:,.0f}" if rev_diff >= 0 else f"-${abs(rev_diff):,.0f}"
            if rev_diff > 0:
                rev_display = f"<span style='color:#2ecc71'>{rev_str}</span>"
            elif rev_diff < 0:
                rev_display = f"<span style='color:#e74c3c'>{rev_str}</span>"
            else:
                rev_display = f"<span style='color:#95a5a6'>{rev_str}</span>"

            case_str = f"+{case_diff}" if case_diff >= 0 else f"{case_diff}"
            if case_diff > 0:
                case_display = f"<span style='color:#2ecc71'>{case_str}äºº</span>"
            elif case_diff < 0:
                case_display = f"<span style='color:#e74c3c'>{case_str}äºº</span>"
            else:
                case_display = f"<span style='color:#95a5a6'>{case_str}äºº</span>"
            
            analysis_text += f"\n        - {agency}ï¼šç‡Ÿæ”¶ {rev_display}ï¼Œå€‹æ¡ˆ {case_display}"

    analysis_text += f"""
    - æœ¬å¹´åº¦è‡³ä»Šï¼Œæ©Ÿæ§‹æ•´é«”å¹³å‡ä½¿ç”¨ç‡ç‚º {avg_rate:.1f}% ï¼Œå±…å®¶æœå‹™ç¸½ç‡Ÿæ”¶é” ${total_revenue:,.0f} ã€‚
    - æ½›åœ¨ç‡Ÿæ”¶æ©Ÿæœƒï¼šè‹¥èƒ½å°‡æ•´é«”ä½¿ç”¨ç‡æå‡è‡³ 85% ï¼Œé æœŸå¯é¡å¤–å¢åŠ  ${gap:,.0f} çš„ç‡Ÿæ”¶ã€‚
    """
    
    # Add Abnormal Case Ratio Insight (Breakdown by Agency)
    # Get data for the latest month to calculate abnormal cases
    latest_month = agg_df['æœˆä»½'].max()
    latest_month_df = agg_df[agg_df['æœˆä»½'] == latest_month].copy()
    latest_month_df['Rate'] = (latest_month_df['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / latest_month_df['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)
    
    analysis_text += f"\n    - {latest_month}æœˆä»½ç•°å¸¸è­¦ç¤ºè©³æƒ… (ä½¿ç”¨ç‡ < 30%)ï¼š"

    agencies = sorted(latest_month_df['æ©Ÿæ§‹'].unique())
    for agency in agencies:
        agency_df = latest_month_df[latest_month_df['æ©Ÿæ§‹'] == agency]
        total_agency_cases = len(agency_df)
        if total_agency_cases > 0:
            low_cases = len(agency_df[agency_df['Rate'] < 30])
            ratio = (low_cases / total_agency_cases * 100)
            analysis_text += f"\n        - {agency}ï¼š{low_cases} ä½ (ä½”è©²æ©Ÿæ§‹ {ratio:.1f}%)"
    
    # Use st.markdown with HTML instead of st.info
    st.markdown(
        f"""
        <div style="background-color: #262730; color: white; padding: 15px; border-radius: 5px; border: 1px solid #464b5d;">
        {analysis_text.replace(chr(10), '<br>')}
        </div>
        """,
        unsafe_allow_html=True
    )
    
    st.markdown("---")
    
    # --- Agency Performance Radar (New) ---
    st.subheader("ğŸ¯ å„æ©Ÿæ§‹ç¶œåˆæ•ˆèƒ½é›·é”åœ–")
    
    # Needs to be based on the LATEST month to be relevant current snapshot
    radar_month = agg_df['æœˆä»½'].max()
    radar_df = agg_df[agg_df['æœˆä»½'] == radar_month].copy()
    
    # Metrics
    # 1. æ•ˆèƒ½ Efficiency: Avg Usage Rate
    # 2. ç”¢å€¼ Value: Rev / Case
    # 3. ç”¢èƒ½ Productivity: Rev / Staff
    # 4. å‹•èƒ½ Potential: % of cases > 80% usage
    # 5. è²¢ç» Impact: Total Rev (Normalized)
    
    radar_metrics = []
    
    radar_agencies = sorted(radar_df['æ©Ÿæ§‹'].unique())
    
    for ag in radar_agencies:
        sub = radar_df[radar_df['æ©Ÿæ§‹'] == ag]
        if sub.empty: continue
        
        # 1. Efficiency
        sub['Rate'] = (sub['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / sub['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)
        eff = sub['Rate'].mean()
        
        # 2. Value
        total_rev = sub['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
        count_case = sub['å€‹æ¡ˆ'].nunique()
        val = (total_rev / count_case) if count_case > 0 else 0
        
        # 3. Productivity
        count_staff = sub['ä¸»è²¬äººå“¡'].nunique()
        prod = (total_rev / count_staff) if count_staff > 0 else 0
        
        # 4. Potential
        high_perf = len(sub[sub['Rate'] >= 80])
        pot = (high_perf / count_case * 100) if count_case > 0 else 0
        
        # 5. Impact 
        imp = total_rev
        
        radar_metrics.append({
            'æ©Ÿæ§‹': ag,
            'æ•ˆèƒ½ (å¹³å‡ä½¿ç”¨ç‡)': eff,
            'ç”¢å€¼ (äººå‡ç‡Ÿæ”¶)': val,
            'ç”¢èƒ½ (ç£å°å¹³å‡ç”¢å‡º)': prod,
            'å‹•èƒ½ (é«˜ç¸¾æ•ˆå€‹æ¡ˆä½”æ¯”)': pot,
            'è²¢ç» (ç¸½ç‡Ÿæ”¶)': imp
        })
        
    radar_data = pd.DataFrame(radar_metrics)
    
    # Normalization (Min-Max to 0-100)
    # Efficiency and Potential are already 0-100 (mostly)
    # Value, Productivity, Impact need scaling
    
    cols_to_norm = ['ç”¢å€¼ (äººå‡ç‡Ÿæ”¶)', 'ç”¢èƒ½ (ç£å°å¹³å‡ç”¢å‡º)', 'è²¢ç» (ç¸½ç‡Ÿæ”¶)']
    
    # Initialize normalized df
    radar_norm = radar_data.copy()
    
    for col in cols_to_norm:
        min_v = radar_data[col].min()
        max_v = radar_data[col].max()
        if max_v > min_v:
            radar_norm[col] = (radar_data[col] - min_v) / (max_v - min_v) * 100
        else:
            radar_norm[col] = 100 # If all same or single agency
            
    # For chart, melt
    radar_melted = radar_norm.melt(
        id_vars=['æ©Ÿæ§‹'], 
        var_name='æŒ‡æ¨™', 
        value_name='åˆ†æ•¸'
    )
    
    fig_radar = px.line_polar(
        radar_melted, 
        r='åˆ†æ•¸', 
        theta='æŒ‡æ¨™', 
        color='æ©Ÿæ§‹', 
        line_close=True,
        title=f"å„æ©Ÿæ§‹äº”åŠ›åˆ†æ ({radar_month}æœˆä»½)",
        range_r=[0, 100]
    )
    fig_radar.update_traces(fill='toself', opacity=0.4)
    st.plotly_chart(fig_radar, use_container_width=True)
    
    with st.expander("æŸ¥çœ‹åŸå§‹æ•¸æ“š"):
        st.dataframe(radar_data.style.format({
            'æ•ˆèƒ½ (å¹³å‡ä½¿ç”¨ç‡)': '{:.1f}%',
            'ç”¢å€¼ (äººå‡ç‡Ÿæ”¶)': '${:,.0f}',
            'ç”¢èƒ½ (ç£å°å¹³å‡ç”¢å‡º)': '${:,.0f}',
            'å‹•èƒ½ (é«˜ç¸¾æ•ˆå€‹æ¡ˆä½”æ¯”)': '{:.1f}%',
            'è²¢ç» (ç¸½ç‡Ÿæ”¶)': '${:,.0f}'
        }))
        
    with st.expander("ğŸ’¡ å¦‚ä½•è§£è®€äº”åŠ›åˆ†æé›·é”åœ– (é»æ“Šå±•é–‹èªªæ˜)"):
        st.markdown("""
        1.  **æ•ˆèƒ½ (å¹³å‡ä½¿ç”¨ç‡)**ï¼šä»£è¡¨é ç®—åŸ·è¡Œæ•ˆç‡ã€‚é«˜åˆ†è¡¨ç¤ºå¤§éƒ¨åˆ†å€‹æ¡ˆé¡åº¦ç”¨å¥½ç”¨æ»¿ï¼›ä½åˆ†è¡¨ç¤ºæœ‰é–’ç½®é¡åº¦ã€‚
        2.  **ç”¢å€¼ (äººå‡ç‡Ÿæ”¶)**ï¼šæ¯ä½å€‹æ¡ˆå¸¶ä¾†çš„ç‡Ÿæ”¶è²¢ç»ã€‚é«˜åˆ†è¡¨ç¤ºå€‹æ¡ˆéœ€æ±‚å¼·åº¦é«˜ï¼›ä½åˆ†è¡¨ç¤ºå¤šç‚ºè¼•åº¦ä½¿ç”¨è€…ã€‚
        3.  **ç”¢èƒ½ (ç£å°å¹³å‡ç”¢å‡º)**ï¼šæ¯ä½ç£å°ç®¡ç†çš„ç‡Ÿæ”¶è¦æ¨¡ã€‚é«˜åˆ†è¡¨ç¤ºç®¡ç†æ•ˆç‡é«˜ï¼Œèƒ½æ‰›èµ·è¼ƒå¤§æ¥­ç¸¾ã€‚
        4.  **å‹•èƒ½ (é«˜ç¸¾æ•ˆå€‹æ¡ˆä½”æ¯”)**ï¼šä½¿ç”¨ç‡ > 80% çš„å„ªè³ªå€‹æ¡ˆæ¯”ä¾‹ã€‚é«˜åˆ†è¡¨ç¤ºä¸»åŠ›å®¢ç¾¤ç©©å®šï¼Œé«”è³ªå¥åº·ã€‚
        5.  **è²¢ç» (ç¸½ç‡Ÿæ”¶)**ï¼šåœ¨æ•´é«”çµ„ç¹”ä¸­çš„ç‡Ÿæ”¶å¸‚ä½”ç‡ã€‚åœ–å½¢è¶Šé£½æ»¿ä»£è¡¨å…¨æ–¹ä½è¡¨ç¾å„ªç•°ã€‚
        """)

    st.divider()

    # --- Trend Chart ---
    st.subheader("ğŸ“ˆ æ©Ÿæ§‹æœˆåº¦ä½¿ç”¨ç‡è¶¨å‹¢")
    fig = px.line(
        agency_monthly, 
        x='æœˆä»½', 
        y='ä½¿ç”¨ç‡(%)', 
        color='æ©Ÿæ§‹', 
        markers=True,
        title='å„æ©Ÿæ§‹æœˆåº¦é¡åº¦ä½¿ç”¨ç‡è¶¨å‹¢'
    )
    fig.update_xaxes(type='category') # Use category to avoid 9.5, 10.5
    st.plotly_chart(fig, use_container_width=True)
    
    # --- Unused Quota Opportunity (New) ---
    # --- Unused Quota Opportunity (New) ---
    st.subheader("ğŸ’° æ½›åœ¨ç‡Ÿæ”¶æ©Ÿæœƒåˆ†æ (å·²ç”¨ vs. å‰©é¤˜)")
    
    # Filter for Opportunity Chart
    opp_agencies = ["å…¨éƒ¨"] + list(agency_monthly['æ©Ÿæ§‹'].unique())
    selected_opp_agency = st.selectbox("é¸æ“‡æ©Ÿæ§‹æŸ¥çœ‹ (æ½›åœ¨æ©Ÿæœƒ)", opp_agencies, key='opp_agency_select')

    chart_opp = agency_monthly.copy()
    
    if selected_opp_agency != "å…¨éƒ¨":
        chart_opp = chart_opp[chart_opp['æ©Ÿæ§‹'] == selected_opp_agency]

    # Stacked Bar: Used Amount vs (Quota - Used Amount)
    chart_opp['å‰©é¤˜é¡åº¦ (æ©Ÿæœƒ)'] = (chart_opp['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'] - chart_opp['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)']).clip(lower=0)
    chart_opp = chart_opp.rename(columns={'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': 'å·²å¯¦ç¾ç‡Ÿæ”¶'})
    
    # We need to melt for stacked chart
    opp_melted = chart_opp.melt(
        id_vars=['æœˆä»½', 'æ©Ÿæ§‹'], 
        value_vars=['å·²å¯¦ç¾ç‡Ÿæ”¶', 'å‰©é¤˜é¡åº¦ (æ©Ÿæœƒ)'],
        var_name='é¡å‹',
        value_name='é‡‘é¡'
    )
    
    # Dynamic Title
    opp_title = f'{selected_opp_agency} - é¡åº¦ä½¿ç”¨ vs. å‰©é¤˜ç©ºé–“' if selected_opp_agency != "å…¨éƒ¨" else 'å…¨æ©Ÿæ§‹ - é¡åº¦ä½¿ç”¨ vs. å‰©é¤˜ç©ºé–“'

    fig_opp = px.bar(
        opp_melted, 
        x='æœˆä»½', 
        y='é‡‘é¡', 
        color='é¡å‹', 
        title=opp_title,
        color_discrete_map={'å·²å¯¦ç¾ç‡Ÿæ”¶': '#2ecc71', 'å‰©é¤˜é¡åº¦ (æ©Ÿæœƒ)': '#95a5a6'}
    )
    fig_opp.update_xaxes(type='category')
    fig_opp.update_traces(width=0.2) # Thinner bars
    st.plotly_chart(fig_opp, use_container_width=True)
    
    # --- Usage Rate Histogram (New) ---
    st.subheader("ğŸ“Š å€‹æ¡ˆä½¿ç”¨ç‡åˆ†ä½ˆè¨ºæ–·")
    # We need row-level data for histogram, not aggregated agency level.
    # agg_df contains row per [Month, Agency, Staff, Case]. perfect.
    
    # Let users pick a month for histogram to see the 'shape' of that month
    hist_month = st.selectbox("é¸æ“‡æœˆä»½æŸ¥çœ‹åˆ†ä½ˆ", sorted(agg_df['æœˆä»½'].unique()), index=len(agg_df['æœˆä»½'].unique())-1, key='hist_month')
    hist_data = agg_df[agg_df['æœˆä»½'] == hist_month].copy() # Use .copy() to avoid SettingWithCopyWarning
    
    hist_data['Rate'] = (hist_data['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / hist_data['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)
    # Cap at 120% for cleaner view if there are outliers
    hist_data['Rate_Capped'] = hist_data['Rate'].apply(lambda x: min(x, 120))
    
    fig_hist = px.histogram(
        hist_data, 
        x='Rate_Capped', 
        nbins=20, 
        title=f"{hist_month} æœˆä»½ - å€‹æ¡ˆä½¿ç”¨ç‡åˆ†ä½ˆåœ–",
        labels={'Rate_Capped': 'ä½¿ç”¨ç‡ (%)'},
        color='æ©Ÿæ§‹', # Stack by Agency
        marginal='box' # Show box plot on top
    )
    fig_hist.add_vline(x=70, line_dash="dash", line_color="green", annotation_text="ç›®æ¨™ 70%")
    st.plotly_chart(fig_hist, use_container_width=True)
    
    with st.expander("ğŸ’¡ å¦‚ä½•è§£è®€å€‹æ¡ˆä½¿ç”¨ç‡åˆ†ä½ˆ (é»æ“Šå±•é–‹èªªæ˜)"):
        st.markdown("""
        æ­¤åœ–è¡¨å±•ç¤ºäº†è©²æœˆä»½æ‰€æœ‰å€‹æ¡ˆçš„ã€Œé¡åº¦ä½¿ç”¨ç‡ã€åˆ†ä½ˆæƒ…å½¢ï¼Œå¹«åŠ©æ‚¨åˆ¤æ–·æ•´é«”ç‡Ÿæ”¶çµæ§‹æ˜¯å¦å¥åº·ã€‚
        
        *   **X è»¸ (ä½¿ç”¨ç‡ %)**ï¼šæ•¸å€¼è¶Šé«˜ä»£è¡¨å€‹æ¡ˆé¡åº¦ç”¨å¾—è¶Šæ»¿ã€‚
        *   **Y è»¸ (Count)**ï¼šä»£è¡¨åœ¨è©²ä½¿ç”¨ç‡å€é–“çš„å€‹æ¡ˆäººæ•¸ã€‚
        *   **ç¶ è‰²è™›ç·š (ç›®æ¨™ 70%)**ï¼šç†æƒ³çš„ç¶“ç‡Ÿç›®æ¨™ç·šã€‚
        
        **è§€å¯Ÿé‡é»ï¼š**
        1.  **å³ååˆ†ä½ˆ (ç†æƒ³)**ï¼šå¤§éƒ¨åˆ†è‰²å¡Šé›†ä¸­åœ¨å³å´ (70%~100%)ï¼Œä»£è¡¨å¤§å¤šæ•¸å€‹æ¡ˆéƒ½ç©©å®šä½¿ç”¨é¡åº¦ã€‚
        2.  **é›™å³°åˆ†ä½ˆ (è­¦è¨Š)**ï¼šè‹¥å·¦å´ (0~30%) å‡ºç¾å¦ä¸€å€‹é«˜å³°ï¼Œä»£è¡¨æœ‰å¤§é‡ã€Œä½ä½¿ç”¨ç‡/ç„¡æ•ˆã€å€‹æ¡ˆï¼Œå¯èƒ½æ˜¯å¹½éˆäººå£æˆ–æ½›åœ¨æµå¤±æˆ¶ã€‚
        3.  **ç®±å‹åœ– (ä¸Šæ–¹)**ï¼š
            *   **ç®±å­ä¸­é–“ç·š**ï¼šä¸­ä½æ•¸ï¼Œä»£è¡¨æœ€ä¸­é–“é‚£ä½å€‹æ¡ˆçš„ä½¿ç”¨ç‡ã€‚
            *   **ç®±å­å¯¬åº¦**ï¼šä¸»è¦å€‹æ¡ˆç¾¤çš„åˆ†ä½ˆç¯„åœã€‚ç®±å­è¶Šçª„è¶Šå¥½ï¼Œä»£è¡¨æœå‹™ä¸€è‡´æ€§é«˜ã€‚
        """)
    
    # Data Table
    with st.expander("æŸ¥çœ‹è©³ç´°æ•¸æ“š"):
        st.dataframe(agency_monthly)
        excel_data = convert_df_to_excel(agency_monthly)
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰æ©Ÿæ§‹åˆ†æå ±è¡¨",
            data=excel_data,
            file_name='æ©Ÿæ§‹æœˆåº¦åˆ†æå ±è¡¨.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

def page_supervisor_performance(agg_df):
    st.header("ğŸ§‘â€ğŸ’¼ ç£å°/äººå“¡ç¸¾æ•ˆåˆ†æ")
    
    # Filter Agency (Optional)
    agencies = agg_df['æ©Ÿæ§‹'].unique()
    selected_agency = st.selectbox("é¸æ“‡æ©Ÿæ§‹ (å…¨é¸å‰‡ä¸å¡«)", ["å…¨éƒ¨"] + list(agencies))
    
    df_to_use = agg_df.copy()
    if selected_agency != "å…¨éƒ¨":
        df_to_use = df_to_use[df_to_use['æ©Ÿæ§‹'] == selected_agency]
    
    # --- Tab 1: Trend Analysis ---
    # --- Tab 2: Workload Matrix (New) ---
    t1, t2, t3 = st.tabs(["ğŸ“ˆ æœˆåº¦è¶¨å‹¢", "âš–ï¸ æ¡ˆé‡ vs. ç¸¾æ•ˆçŸ©é™£", "ğŸ† æ¥­ç¸¾æ’è¡Œ"])
    
    with t1:
        # Aggregation for Trend
        staff_monthly = df_to_use.groupby(['æœˆä»½', 'ä¸»è²¬äººå“¡']).agg({
            'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦': 'sum',
            'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': 'sum'
        }).reset_index()
        
        staff_monthly['ä½¿ç”¨ç‡(%)'] = (staff_monthly['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / staff_monthly['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100).round(2)
        
        fig_trend = px.line(
            staff_monthly, 
            x='æœˆä»½', 
            y='ä½¿ç”¨ç‡(%)', 
            color='ä¸»è²¬äººå“¡', 
            markers=True,
            title=f'å„ç£å°/äººå“¡æœˆåº¦ä½¿ç”¨ç‡è¶¨å‹¢'
        )
        fig_trend.update_xaxes(type='category')
        st.plotly_chart(fig_trend, use_container_width=True)

    with t2:
        st.markdown("### ç£å°æ¡ˆé‡çŸ©é™£")
        st.caption("Xè»¸ï¼šè² è²¬å€‹æ¡ˆæ•¸ (æ¡ˆé‡) | Yè»¸ï¼šå¹³å‡é¡åº¦ä½¿ç”¨ç‡ (ç¸¾æ•ˆ) | é»çš„å¤§å°ï¼šç¸½åˆ†é…é¡åº¦è¦æ¨¡")
        
        # 1. Month Selector
        months = sorted(df_to_use['æœˆä»½'].unique())
        matrix_month = st.selectbox("é¸æ“‡æœˆä»½é€²è¡Œåˆ†æ", months, index=len(months)-1 if months else 0, key='matrix_month')
        
        matrix_data = df_to_use[df_to_use['æœˆä»½'] == matrix_month]
        
        # 2. Local Agency Filter (If global is 'All', allow specific drill down here)
        if selected_agency == "å…¨éƒ¨":
            matrix_agencies = matrix_data['æ©Ÿæ§‹'].unique()
            local_agency = st.selectbox("åœ¨çŸ©é™£ä¸­ç¯©é¸æ©Ÿæ§‹", ["å…¨éƒ¨"] + list(matrix_agencies), key='matrix_agency_filter')
            if local_agency != "å…¨éƒ¨":
                matrix_data = matrix_data[matrix_data['æ©Ÿæ§‹'] == local_agency]

        # Aggregation by [Agency, Staff] to avoid name collisions
        staff_matrix = matrix_data.groupby(['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡']).agg({
            'å€‹æ¡ˆ': 'count',
            'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦': 'sum',
            'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': 'sum'
        }).reset_index()
        
        staff_matrix['å¹³å‡ä½¿ç”¨ç‡(%)'] = (staff_matrix['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / staff_matrix['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100).round(2)
        staff_matrix = staff_matrix.rename(columns={'å€‹æ¡ˆ': 'å€‹æ¡ˆæ•¸'})
        
        # Quadrant Lines
        if not staff_matrix.empty:
            avg_load = staff_matrix['å€‹æ¡ˆæ•¸'].mean()
            avg_rate = staff_matrix['å¹³å‡ä½¿ç”¨ç‡(%)'].mean()
        else:
            avg_load = 0
            avg_rate = 0
        
        # Color strategy: If filtering specific agency, color by Staff. If All, color by Agency? 
        # Or always color by Staff but show Agency in hover. 
        # If too many staff, color by Agency is better for "All".
        color_col = 'ä¸»è²¬äººå“¡'
        if selected_agency == "å…¨éƒ¨" and (pd.isna(local_agency) if 'local_agency' not in locals() else local_agency == "å…¨éƒ¨"):
             # If displaying ALL agencies, maybe color by Agency to distinguish clusters?
             # But user wants to identify Staff. Let's stick to Staff but add Agency to hover.
             pass

        fig_matrix = px.scatter(
            staff_matrix,
            x='å€‹æ¡ˆæ•¸',
            y='å¹³å‡ä½¿ç”¨ç‡(%)',
            color='ä¸»è²¬äººå“¡', # Color by Staff Name
            # symbol='ä¸»è²¬äººå“¡', # Removed to use default dots (circles)
            size='ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦', 
            hover_data=['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆæ•¸', 'å¹³å‡ä½¿ç”¨ç‡(%)', 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'],
            text='ä¸»è²¬äººå“¡',
            title=f"{matrix_month} æœˆä»½ - ç£å°æ¡ˆé‡æ•ˆèƒ½çŸ©é™£"
        )
        fig_matrix.update_traces(textposition='top center')
        
        # Add Reference Lines
        fig_matrix.add_hline(y=avg_rate, line_dash="dash", line_color="green", annotation_text=f"å¹³å‡ä½¿ç”¨ç‡: {avg_rate:.1f}%")
        fig_matrix.add_vline(x=avg_load, line_dash="dash", line_color="orange", annotation_text=f"å¹³å‡æ¡ˆé‡: {avg_load:.1f}")
        
        st.plotly_chart(fig_matrix, use_container_width=True)

    with t3:
        st.markdown("### ğŸ† ç£å°æ¥­ç¸¾æ’è¡Œ")
        
        # Reuse existing selectors? 
        # Ideally, ranking is also monthly.
        # Let's use a fresh selector or sync? Sync is hard across tabs without session state shenanigans.
        # Let's just add a simple selector for this tab or reuse the one from Matrix if we move it up?
        # Moving selectors up to the main page level is cleaner.
        
        # But to avoid refactoring the whole function, let's just add a month selector here locally.
        rank_month = st.selectbox("é¸æ“‡æ’åºæœˆä»½", months, index=len(months)-1 if months else 0, key='rank_month')
        
        rank_data = df_to_use[df_to_use['æœˆä»½'] == rank_month]
        
        # Group by Staff
        staff_rank = rank_data.groupby(['ä¸»è²¬äººå“¡', 'æ©Ÿæ§‹']).agg({
            'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': 'sum',
            'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦': 'sum',
            'å€‹æ¡ˆ': 'count'
        }).reset_index()
        
        staff_rank['ä½¿ç”¨ç‡(%)'] = (staff_rank['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / staff_rank['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100).round(2)
        
        # Sort by Revenue (Performance)
        staff_rank = staff_rank.sort_values('æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)', ascending=True) # Ascending for horizontal bar
        
        # Plot
        fig_rank = px.bar(
            staff_rank,
            x='æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)',
            y='ä¸»è²¬äººå“¡',
            orientation='h',
            title=f"{rank_month} æœˆä»½ - ç£å°æ¥­ç¸¾æ’è¡Œ (ä¾ç‡Ÿæ”¶)",
            text_auto='.2s',
            color='æ©Ÿæ§‹', # Useful if 'All' agencies selected
            hover_data=['ä½¿ç”¨ç‡(%)', 'å€‹æ¡ˆ']
        )
        fig_rank.update_traces(textposition='outside')
        fig_rank.update_layout(yaxis={'categoryorder':'total ascending'})
        
        st.plotly_chart(fig_rank, use_container_width=True)
        
        # Table View
        st.dataframe(
            staff_rank.sort_values('æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)', ascending=False)
            .style.format({'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)': '{:,.0f}', 'ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦': '{:,.0f}', 'ä½¿ç”¨ç‡(%)': '{:.1f}%'})
            .background_gradient(subset=['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'], cmap='Greens')
        )

def page_case_detail(raw_df, agg_df):
    st.header("ğŸ” å€‹æ¡ˆè©³ç´°åˆ†æ")
    
    # Filters
    col1, col2, col3 = st.columns(3)
    months = sorted(agg_df['æœˆä»½'].unique())
    with col1:
        current_month = st.selectbox("é¸æ“‡æœˆä»½", months, index=len(months)-1 if months else 0)
    
    agencies = agg_df[agg_df['æœˆä»½'] == current_month]['æ©Ÿæ§‹'].unique()
    with col2:
        agency = st.selectbox("æ©Ÿæ§‹", agencies)
        
    staffs = agg_df[(agg_df['æœˆä»½'] == current_month) & (agg_df['æ©Ÿæ§‹'] == agency)]['ä¸»è²¬äººå“¡'].unique()
    with col3:
        staff = st.selectbox("ä¸»è²¬äººå“¡", staffs)
        
    # Data Prep
    # Get Current Month Data
    current_data = agg_df[
        (agg_df['æœˆä»½'] == current_month) & 
        (agg_df['æ©Ÿæ§‹'] == agency) & 
        (agg_df['ä¸»è²¬äººå“¡'] == staff)
    ].copy()
    
    # Determine 'Previous Month' for Trend
    # Need to handle string months properly. Assuming they are sortable.
    # Ideally, we should convert to int if possible, but let's stick to list index.
    curr_idx = months.index(current_month)
    prev_month = months[curr_idx - 1] if curr_idx > 0 else None
    
    prev_data = None
    if prev_month:
        prev_data = agg_df[
            (agg_df['æœˆä»½'] == prev_month) & 
            (agg_df['æ©Ÿæ§‹'] == agency) & 
            (agg_df['ä¸»è²¬äººå“¡'] == staff)
        ].set_index('å€‹æ¡ˆ')['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] # Need ratio? Or just used amount?
        # Re-calculate usage rate for prev month lookup
        prev_data_full = agg_df[
             (agg_df['æœˆä»½'] == prev_month) & 
             (agg_df['æ©Ÿæ§‹'] == agency) & 
             (agg_df['ä¸»è²¬äººå“¡'] == staff)
        ].copy()
        prev_data_full['Rate'] = (prev_data_full['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / prev_data_full['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)
        prev_map = prev_data_full.set_index('å€‹æ¡ˆ')['Rate']

    # Display Cases
    # Avoid div by zero
    current_data['Rate'] = (current_data['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / current_data['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100).round(2)
    
    st.markdown("### å€‹æ¡ˆåˆ—è¡¨")
    
    for _, row in current_data.iterrows():
        case_name = row['å€‹æ¡ˆ']
        rate = row['Rate']
        
        # Trend Logic
        diff = 0
        has_prev = False
        trend_str = ""
        
        if prev_month and prev_data is not None and case_name in prev_map:
            prev_rate = prev_map[case_name]
            diff = rate - prev_rate
            has_prev = True
            
            if diff > 0:
                trend_str = f":green[â†‘ {diff:.1f}%]"
            elif diff < 0:
                trend_str = f":red[â†“ {abs(diff):.1f}%]"
            else:
                trend_str = ":gray[â– 0.0%]"
        
        # UI Card (Expander)
        status = row.get('æœå‹™ä½¿ç”¨ç‹€æ…‹', 'æœªçŸ¥')
        # Title with Colored Markdown
        with st.expander(f"{case_name} ({status}) | æœ¬æœˆä½¿ç”¨ç‡: {rate}% | {trend_str}"):
            
            # Metrics Row (Replaces the old st.info line)
            m1, m2, m3 = st.columns(3)
            m1.metric("é¡åº¦ä½¿ç”¨ç‡", f"{rate}%", f"{diff:.1f}%" if has_prev else None)
            m2.metric("åˆ†é…é¡åº¦", f"{row['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦']:,.0f}")
            m3.metric("ä½¿ç”¨é¡åº¦", f"{row['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)']:,.0f}")
            
            # Drill Down: Show detailed service items from RAW dataframe
            curr_details = raw_df[
                (raw_df['æœˆä»½'] == current_month) & 
                (raw_df['æ©Ÿæ§‹'] == agency) & 
                (raw_df['ä¸»è²¬äººå“¡'] == staff) & 
                (raw_df['å€‹æ¡ˆ'] == case_name)
            ]
            
            # Aggregate to handle potential duplicate entries per item and clean up view
            curr_agg = curr_details.groupby('æœå‹™é …ç›®').agg({
                'æ”¿åºœæœå‹™é …ç›®å–®åƒ¹': 'max', # Assumption: price is constant
                'æœå‹™ç´€éŒ„çµ„æ•¸': 'sum',
                'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': 'sum'
            }).reset_index()

            if prev_month:
                # Get Previous Month Details
                prev_details = raw_df[
                    (raw_df['æœˆä»½'] == prev_month) & 
                    (raw_df['æ©Ÿæ§‹'] == agency) & 
                    (raw_df['ä¸»è²¬äººå“¡'] == staff) & 
                    (raw_df['å€‹æ¡ˆ'] == case_name)
                ]
                
                prev_agg = prev_details.groupby('æœå‹™é …ç›®').agg({
                    'æ”¿åºœæœå‹™é …ç›®å–®åƒ¹': 'max',
                    'æœå‹™ç´€éŒ„çµ„æ•¸': 'sum',
                    'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': 'sum'
                }).reset_index().rename(columns={
                    'æ”¿åºœæœå‹™é …ç›®å–®åƒ¹': 'å–®åƒ¹(ä¸Šæœˆ)',
                    'æœå‹™ç´€éŒ„çµ„æ•¸': 'çµ„æ•¸(ä¸Šæœˆ)', 
                    'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': 'é‡‘é¡(ä¸Šæœˆ)'
                })
                
                # Merge
                merged_details = pd.merge(curr_agg, prev_agg, on='æœå‹™é …ç›®', how='outer').fillna(0)
                
                # Coalesce Unit Price: Use Current if > 0, else Prev
                merged_details['æ”¿åºœæœå‹™é …ç›®å–®åƒ¹'] = merged_details.apply(
                    lambda x: x['æ”¿åºœæœå‹™é …ç›®å–®åƒ¹'] if x['æ”¿åºœæœå‹™é …ç›®å–®åƒ¹'] > 0 else x['å–®åƒ¹(ä¸Šæœˆ)'], axis=1
                )
                
                # Calculate Deltas
                merged_details['é‡‘é¡å·®ç•°'] = merged_details['æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦'] - merged_details['é‡‘é¡(ä¸Šæœˆ)']
                merged_details['çµ„æ•¸å·®ç•°'] = merged_details['æœå‹™ç´€éŒ„çµ„æ•¸'] - merged_details['çµ„æ•¸(ä¸Šæœˆ)']
                
                # Sort by Absolute Amount Difference to show most impactful changes first
                merged_details['abs_diff'] = merged_details['é‡‘é¡å·®ç•°'].abs()
                merged_details = merged_details.sort_values('abs_diff', ascending=False).drop(columns=['abs_diff'])
                
                # Formatting Columns
                display_cols = ['æœå‹™é …ç›®', 'æ”¿åºœæœå‹™é …ç›®å–®åƒ¹', 'æœå‹™ç´€éŒ„çµ„æ•¸', 'çµ„æ•¸å·®ç•°', 'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦', 'é‡‘é¡å·®ç•°']
                
                st.dataframe(
                    merged_details[display_cols].style
                    .format({
                        'æ”¿åºœæœå‹™é …ç›®å–®åƒ¹': '{:.0f}', 
                        'æœå‹™ç´€éŒ„çµ„æ•¸': '{:.0f}', 
                        'çµ„æ•¸å·®ç•°': '{:+.0f}',
                        'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': '{:,.0f}',
                        'é‡‘é¡å·®ç•°': '{:+,.0f}'
                    })
                    .background_gradient(subset=['é‡‘é¡å·®ç•°'], cmap='RdBu', vmin=-5000, vmax=5000)
                    .applymap(lambda v: 'color: transparent' if v == 0 else '', subset=['çµ„æ•¸å·®ç•°', 'é‡‘é¡å·®ç•°']) # Visual cleanup
                )
            else:
                # Fallback if no prev month
                st.dataframe(curr_agg.style.format({
                    'æ”¿åºœæœå‹™é …ç›®å–®åƒ¹': '{:.0f}', 
                    'æœå‹™ç´€éŒ„çµ„æ•¸': '{:.0f}',
                    'æœå‹™ç´€éŒ„ä½¿ç”¨é¡åº¦': '{:,.0f}'
                }))

def page_comparison(agg_df):
    st.header("âš–ï¸ é›™æœˆä»½è¶…ç´šæ¯”å°")
    
    months = sorted(agg_df['æœˆä»½'].unique())
    if len(months) < 2:
        st.warning("è³‡æ–™ä¸è¶³å…©å€‹æœˆï¼Œç„¡æ³•é€²è¡Œæ¯”å°ã€‚")
        return
        
    col1, col2 = st.columns(2)
    with col1:
        month_a = st.selectbox("åŸºæº–æœˆä»½ (A)", months, index=len(months)-2)
    with col2:
        month_b = st.selectbox("æ¯”è¼ƒæœˆä»½ (B)", months, index=len(months)-1)
        
    if month_a == month_b:
        st.info("è«‹é¸æ“‡ä¸åŒçš„æœˆä»½é€²è¡Œæ¯”å°ã€‚")
        return
    
    # Global Agency Filter
    agencies = sorted(agg_df['æ©Ÿæ§‹'].unique())
    selected_agency = st.selectbox("é¸æ“‡æ©Ÿæ§‹ç¯„åœ", ["å…¨éƒ¨"] + list(agencies), key='comp_global_agency')
    
    # Get Data
    data_a = agg_df[agg_df['æœˆä»½'] == month_a]
    data_b = agg_df[agg_df['æœˆä»½'] == month_b]
    
    # Apply Filter
    if selected_agency != "å…¨éƒ¨":
        data_a = data_a[data_a['æ©Ÿæ§‹'] == selected_agency]
        data_b = data_b[data_b['æ©Ÿæ§‹'] == selected_agency]
    
    # Metrics Calculation
    def get_metrics(df):
        rev = df['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
        quota = df['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].sum()
        rate = (rev / quota * 100) if quota > 0 else 0
        cases = df['å€‹æ¡ˆ'].nunique()
        return rev, rate, cases
        
    rev_a, rate_a, cases_a = get_metrics(data_a)
    rev_b, rate_b, cases_b = get_metrics(data_b)
    
    # Display Side-by-Side Metrics
    st.markdown("### é—œéµæŒ‡æ¨™å·®ç•°")
    c1, c2, c3 = st.columns(3)
    
    rev_diff = rev_b - rev_a
    c1.metric("ç¸½ç‡Ÿæ”¶ (B vs A)", f"${rev_b:,.0f}", f"{rev_diff:,.0f}")
    c2.metric("å¹³å‡ä½¿ç”¨ç‡ (B vs A)", f"{rate_b:.1f}%", f"{rate_b - rate_a:.1f}%")
    c3.metric("æœå‹™å€‹æ¡ˆæ•¸ (B vs A)", f"{cases_b}", f"{cases_b - cases_a}")
    
    st.markdown("---")
    
    # Drill Down by Agency
    # If specific agency selected, this chart is less useful (1 bar), but still ok.
    if selected_agency == "å…¨éƒ¨":
        st.subheader("å„æ©Ÿæ§‹å·®ç•°æ˜ç´°")
    else:
        st.subheader(f"{selected_agency} - ç‡Ÿæ”¶å·®ç•°")
    
    group_a = data_a.groupby('æ©Ÿæ§‹')['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
    group_b = data_b.groupby('æ©Ÿæ§‹')['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'].sum()
    
    # Combine
    comp_df = pd.DataFrame({'åŸºæº–æœˆ': group_a, 'æ¯”è¼ƒæœˆ': group_b}).fillna(0)
    comp_df['å·®ç•°é‡‘é¡'] = comp_df['æ¯”è¼ƒæœˆ'] - comp_df['åŸºæº–æœˆ']
    comp_df['æˆé•·ç‡(%)'] = (comp_df['å·®ç•°é‡‘é¡'] / comp_df['åŸºæº–æœˆ'].replace(0, 1) * 100).round(1)
    
    st.dataframe(comp_df.style.format("{:,.0f}", subset=['åŸºæº–æœˆ', 'æ¯”è¼ƒæœˆ', 'å·®ç•°é‡‘é¡']).format("{:.1f}%", subset=['æˆé•·ç‡(%)']))
    
    # Visual Delta
    fig = px.bar(
        comp_df.reset_index(), 
        x='æ©Ÿæ§‹', 
        y='å·®ç•°é‡‘é¡', 
        title=f"å„æ©Ÿæ§‹ç‡Ÿæ”¶å·®ç•° ({month_b}æœˆ - {month_a}æœˆ)",
        text='å·®ç•°é‡‘é¡',
        color='å·®ç•°é‡‘é¡',
        color_continuous_scale=['red', 'gray', 'green']
    )
    fig.update_traces(width=0.2) # Thinner bars
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # --- Case Level Comparison (New) ---
    st.subheader("ğŸ” å€‹æ¡ˆå±¤ç´šè®ŠåŒ–åˆ†æ (Top 10)")
    
    # No extra filter needed here, using global data_a/data_b
    
    # Prepare Merge
    cases_a = data_a.copy()
    cases_b = data_b.copy()
    
    cases_a['Rate_A'] = (cases_a['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / cases_a['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)
    cases_b['Rate_B'] = (cases_b['æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)'] / cases_b['ç…§ç®¡é‡‘é¡åˆ†é…é¡åº¦'].replace(0, 1) * 100)
    
    # Merge on Agency (needed if 'All'), Staff and Case
    # Grouping key should be unique. [Agency, Staff, Case]
    
    merged_cases = pd.merge(
        cases_a[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_A', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)']],
        cases_b[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_B', 'æœå‹™ç´€éŒ„(ä¸å«è‡ªè²»)']],
        on=['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ'],
        how='outer',
        suffixes=('_A', '_B')
    )
    
    # Fill NA for calculation (0 means didn't exist or 0 usage)
    merged_cases['Rate_A_Fill'] = merged_cases['Rate_A'].fillna(0)
    merged_cases['Rate_B_Fill'] = merged_cases['Rate_B'].fillna(0)
    
    merged_cases['å·®ç•°(%)'] = merged_cases['Rate_B_Fill'] - merged_cases['Rate_A_Fill']
    merged_cases['ç‹€æ…‹'] = merged_cases.apply(
        lambda x: 'ğŸ†• æ–°æ¡ˆ' if pd.isna(x['Rate_A']) else ('âŒ çµæ¡ˆ/ä¸­æ–·' if pd.isna(x['Rate_B']) else 'æœå‹™ä¸­'), 
        axis=1
    )
    
    # Scatter Plot: Rate A vs Rate B
    # Only for common cases to avoid clutter at 0 axes
    common_cases = merged_cases[merged_cases['ç‹€æ…‹'] == 'æœå‹™ä¸­']
    
    if not common_cases.empty:
        col_growth, col_decline = st.columns(2)
        
        with col_growth:
            st.markdown("#### ğŸ† è®ŠåŒ–å¹…åº¦æ’è¡Œ (Top 10 æˆé•·)")
            top_growth = common_cases.sort_values('å·®ç•°(%)', ascending=False).head(10)
            st.dataframe(
                top_growth[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_A', 'Rate_B', 'å·®ç•°(%)']]
                .style.format({'Rate_A': '{:.1f}%', 'Rate_B': '{:.1f}%', 'å·®ç•°(%)': '{:+.1f}%'})
                .background_gradient(subset=['å·®ç•°(%)'], cmap='Greens')
            )
            
        with col_decline:
            st.markdown("#### ğŸ“‰ è®ŠåŒ–å¹…åº¦æ’è¡Œ (Top 10 è¡°é€€)")
            top_decline = common_cases.sort_values('å·®ç•°(%)', ascending=True).head(10)
            st.dataframe(
                top_decline[['æ©Ÿæ§‹', 'ä¸»è²¬äººå“¡', 'å€‹æ¡ˆ', 'Rate_A', 'Rate_B', 'å·®ç•°(%)']]
                .style.format({'Rate_A': '{:.1f}%', 'Rate_B': '{:.1f}%', 'å·®ç•°(%)': '{:+.1f}%'})
                .background_gradient(subset=['å·®ç•°(%)'], cmap='Reds_r')
            )
    else:
        st.info("åœ¨æ­¤ç¯„åœå…§ï¼Œå…©æœŸé–“ç„¡å…±åŒæœå‹™å€‹æ¡ˆã€‚")

if __name__ == "__main__":
    main()
